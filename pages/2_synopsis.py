"""
pages/2_synopsis.py

ì¤„ê±°ë¦¬ íƒìƒ‰ í˜ì´ì§€
- ì˜í™”/ë“œë¼ë§ˆ íƒ­ìœ¼ë¡œ êµ¬ë¶„
- TF-IDF ë¶„ì„
- BERTopic í´ëŸ¬ìŠ¤í„°/í† í”½ ë¶„ì„ (ì›ë³¸ UMAP)
- ëŒ€í‘œ ì‘í’ˆ íƒ­ ì¶”ê°€
"""
import os
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

from components import page_header
from utils.loader import load_tfidf_keywords
from utils.wordcloud_utils import generate_wordcloud_image
from utils.topic_mappings import get_cluster_name, get_topic_name

# âœ… í°íŠ¸ ê²½ë¡œë¥¼ ìƒëŒ€ ê²½ë¡œë¡œ ë³€ê²½ (ë°°í¬ í™˜ê²½ í˜¸í™˜)
BASE_DIR = os.path.dirname(os.path.dirname(__file__))  # pages/ â†’ streamlit_app/
FONT_PATH = os.path.join(BASE_DIR, "assets", "fonts", "MaruBuri-Bold.ttf")

# í°íŠ¸ íŒŒì¼ì´ ì—†ìœ¼ë©´ None ì‚¬ìš© (ê¸°ë³¸ í°íŠ¸)
if not os.path.exists(FONT_PATH):
    FONT_PATH = None

# =============================================================================
# í˜ì´ì§€ í—¤ë”
# =============================================================================
page_header(
    title="ğŸ“ ì¤„ê±°ë¦¬ íƒìƒ‰",
    subtitle="TF-IDF ë¶„ì„ ë° BERTopic í´ëŸ¬ìŠ¤í„° ë¶„ì„"
)

st.markdown(
    """
    <style>
    /* Selectbox / Multiselect ì™„ì „ í°ìƒ‰ */
    div[data-baseweb="select"] > div {
        background-color: white !important;
        color: black !important;
    }
    span[data-baseweb="tag"] {
        background-color: #e6f0ff !important;
        color: black !important;
        border-radius: 6px;
    }
    div[data-baseweb="popover"], div[data-baseweb="menu"] {
        background-color: white !important;
        color: black !important;
        border: 1px solid #d0d0d0 !important;
    }
    div[data-baseweb="menu"] * { color: black !important; }
    li[role="option"] {
        background-color: white !important;
        color: black !important;
    }
    li[role="option"]:hover { background-color: #f2f2f2 !important; }
    li[aria-selected="true"] {
        background-color: #e6f0ff !important;
        font-weight: 600;
    }
    
    /* í‚¤ì›Œë“œ íƒœê·¸ ìŠ¤íƒ€ì¼ - í¬ê¸° ì¦ê°€ */
    .keyword-tag {
        display: inline-block;
        padding: 8px 16px;  /* ì¦ê°€: 4px 12px â†’ 8px 16px */
        margin: 6px;  /* ì¦ê°€: 4px â†’ 6px */
        background-color: #2596be;
        color: white;
        border-radius: 20px;  /* ì¦ê°€: 16px â†’ 20px */
        font-size: 16px;  /* ì¦ê°€: 13px â†’ 16px */
        font-weight: 600;  /* ì¦ê°€: 500 â†’ 600 */
    }
    
    /* ëŒ€í‘œ ì‘í’ˆ ì¹´ë“œ */
    .rep-work-card {
        background: white;
        border: 1px solid #e0e0e0;
        border-radius: 12px;
        padding: 20px;
        margin-bottom: 20px;
    }
    
    .rep-work-card h4 {
        color: #2596be;
        margin-bottom: 12px;
        font-size: 18px;
    }
    
    /* ì˜í™” ì œëª© í¬ê¸° ì¦ê°€ */
    .movie-title {
        font-size: 20px !important;
        font-weight: 600 !important;
        text-align: left !important;
        margin-top: 4px !important;
        margin-bottom: 20px !important;
        margin-left: 0 !important;
        padding-left: 0 !important;
        color: #333;
        line-height: 1.5;
        width: 100%;
        display: block;
    }
    
    /* Streamlit ì´ë¯¸ì§€ ì•„ë˜ ì—¬ë°± ì œê±° */
    .stImage {
        margin-bottom: 0px !important;
    }
    
    img {
        margin-bottom: 0px !important;
        display: block;
    }
    </style>
    """,
    unsafe_allow_html=True
)


# =============================================================================
# ê³µí†µ ì‹œê°í™” í•¨ìˆ˜
# =============================================================================

def create_topic_map(df_map, df_clusters, category, selected_items, 
                     view_mode, content_type, content_type_label="ë“œë¼ë§ˆ"):
    """UMAP í† í”½ ë§µ ìƒì„±"""
    df = df_map.copy()
    
    # ì»¬ëŸ¼ëª… í‘œì¤€í™”
    if 'í´ëŸ¬ìŠ¤í„°' in df_clusters.columns:
        cluster_col = 'í´ëŸ¬ìŠ¤í„°'
        topic_col = 'í† í”½ë²ˆí˜¸'
    else:
        cluster_col = 'cluster'
        topic_col = 'topic_id'
    
    # í´ëŸ¬ìŠ¤í„° ë§¤í•‘
    if 'cluster' not in df.columns:
        topic_to_cluster = dict(zip(
            df_clusters[topic_col], 
            df_clusters[cluster_col]
        ))
        df['cluster'] = df['topic'].map(topic_to_cluster).fillna(-1).astype(int)
    
    # UMAP ì¢Œí‘œ í™•ì¸
    if 'umap_x' not in df.columns or 'umap_y' not in df.columns:
        st.warning("UMAP ì¢Œí‘œê°€ ì—†ì–´ ì‹œê°í™”ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return go.Figure()
    
    x_col, y_col = 'umap_x', 'umap_y'
    
    # í•„í„°ë§
    if view_mode == 'cluster' and selected_items:
        df = df[df['cluster'].isin(selected_items)]
    elif view_mode == 'topic' and selected_items:
        df = df[df['topic'].isin(selected_items)]
    
    if len(df) == 0:
        fig = go.Figure()
        fig.add_annotation(text="ì„ íƒí•œ í•­ëª©ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.", 
                          xref="paper", yref="paper", x=0.5, y=0.5, showarrow=False)
        return fig
    
    # ìƒ‰ìƒ ê·¸ë£¹ ì„¤ì •
    if view_mode == 'cluster':
        df['display_name'] = df['cluster'].apply(
            lambda x: get_cluster_name(content_type, category, x) if x != -1 else "Noise"
        )
        df['color_group'] = df['display_name']
        color_seq = px.colors.qualitative.Set2
    else:
        df['display_name'] = df['topic'].apply(
            lambda x: get_topic_name(content_type, category, x) if x != -1 else "Noise"
        )
        df['color_group'] = df['display_name']
        color_seq = px.colors.qualitative.Light24
    
    # ì •ë ¬
    if view_mode == 'cluster':
        df['sort_key'] = df['cluster'].apply(lambda x: 999 if x == -1 else x)
    else:
        df['sort_key'] = df['topic'].apply(lambda x: 999 if x == -1 else x)
    df = df.sort_values('sort_key')
    
    # í˜¸ë²„ ë°ì´í„°
    hover_data = {'title': True, 'topic': True, 'display_name': True, x_col: False, y_col: False}
    if 'hit_score' in df.columns:
        df['hit_score_fmt'] = df['hit_score'].round(4)
        hover_data['hit_score_fmt'] = ':.4f'
    
    # íƒ€ì´í‹€
    category_label = "ğŸŸ¢ í¥í–‰ì‘" if category == 'hit' else "ğŸ”´ ë¹„í¥í–‰ì‘"
    view_label = "í´ëŸ¬ìŠ¤í„°" if view_mode == 'cluster' else "í† í”½"
    title = f"{category_label} {content_type_label} {view_label} Map"
    
    fig = px.scatter(
        df, x=x_col, y=y_col, color='color_group',
        hover_data=hover_data, title=title,
        color_discrete_sequence=color_seq,
        labels={x_col: 'UMAP X', y_col: 'UMAP Y', 'display_name': view_label}
    )
    
    fig.update_traces(marker=dict(size=10, opacity=0.75, line=dict(width=0.5, color='DarkSlateGray')))
    fig.update_layout(
        height=600,
        plot_bgcolor='white',
        paper_bgcolor='white',
        legend=dict(
            orientation="v", 
            yanchor="top", 
            y=0.99, 
            xanchor="left", 
            x=1.02,
            bgcolor='rgba(255,255,255,0.9)',
            bordercolor='#d0d0d0',
            borderwidth=1,
            font=dict(color='black')
        ),
        margin=dict(r=250),
        title_font=dict(color='black', size=16),
        xaxis=dict(
            showgrid=True, 
            gridwidth=1, 
            gridcolor='rgba(200,200,200,0.3)',
            title_font=dict(color='black'),
            tickfont=dict(color='black')
        ),
        yaxis=dict(
            showgrid=True, 
            gridwidth=1, 
            gridcolor='rgba(200,200,200,0.3)',
            title_font=dict(color='black'),
            tickfont=dict(color='black')
        )
    )
    
    return fig


def create_keyword_comparison_chart(df_comparison, top_n=20):
    """í‚¤ì›Œë“œ ë¹„êµ ì°¨íŠ¸"""
    df = df_comparison.head(top_n)
    
    fig = make_subplots(
        rows=1, cols=2,
        subplot_titles=("ğŸŸ¢ í¥í–‰ì‘ ê³ ìœ  í‚¤ì›Œë“œ", "ğŸ”´ ë¹„í¥í–‰ì‘ ê³ ìœ  í‚¤ì›Œë“œ"),
        horizontal_spacing=0.15
    )
    
    hit_kw = df[df['hit_unique_keyword'].notna() & (df['hit_unique_keyword'] != '')]
    if len(hit_kw) > 0:
        fig.add_trace(go.Bar(
            y=hit_kw['hit_unique_keyword'], x=hit_kw['hit_unique_score'],
            orientation='h', marker_color='mediumseagreen', name='í¥í–‰ì‘', showlegend=False,
            textfont=dict(color='black')
        ), row=1, col=1)
    
    flop_kw = df[df['flop_unique_keyword'].notna() & (df['flop_unique_keyword'] != '')]
    if len(flop_kw) > 0:
        fig.add_trace(go.Bar(
            y=flop_kw['flop_unique_keyword'], x=flop_kw['flop_unique_score'],
            orientation='h', marker_color='indianred', name='ë¹„í¥í–‰ì‘', showlegend=False,
            textfont=dict(color='black')
        ), row=1, col=2)
    
    fig.update_layout(
        height=600, 
        plot_bgcolor='white',
        paper_bgcolor='white',
        xaxis=dict(
            title_text="c-TF-IDF Score",
            title_font=dict(color='black'),
            tickfont=dict(color='black')
        ),
        xaxis2=dict(
            title_text="c-TF-IDF Score",
            title_font=dict(color='black'),
            tickfont=dict(color='black')
        ),
        # ğŸ‘‡ğŸ‘‡ ì—¬ê¸° ì¶”ê°€
        yaxis=dict(
            tickfont=dict(color='black', size=16)   # â† ê¸°ë³¸ 12 â†’ 14
        ),
        yaxis2=dict(
            tickfont=dict(color='black', size=16)
        ),
        annotations=[
            dict(
                text="ğŸŸ¢ í¥í–‰ì‘ ê³ ìœ  í‚¤ì›Œë“œ",
                xref="paper", yref="paper",
                x=0.22, y=1.08,
                xanchor="center", yanchor="bottom",
                showarrow=False,
                font=dict(size=18, color='black')
            ),
            dict(
                text="ğŸ”´ ë¹„í¥í–‰ì‘ ê³ ìœ  í‚¤ì›Œë“œ",
                xref="paper", yref="paper",
                x=0.78, y=1.08,
                xanchor="center", yanchor="bottom",
                showarrow=False,
                font=dict(size=18, color='black')
            )
        ]
    )
    return fig


def create_distribution_chart(df_map, view_mode, category, content_type, content_type_label="ë“œë¼ë§ˆ"):
    """í´ëŸ¬ìŠ¤í„°/í† í”½ë³„ ë¶„í¬ ì°¨íŠ¸ - Noise ì œê±°, ìƒ‰ìƒ ë³€ê²½, yì¶• ì¡°ì •"""
    if view_mode == 'cluster':
        group_col = 'cluster'
        label = 'í´ëŸ¬ìŠ¤í„°'
        df_map = df_map.copy()
        df_map['display_name'] = df_map[group_col].apply(
            lambda x: get_cluster_name(content_type, category, x) if x != -1 else "Noise"
        )
    else:
        group_col = 'topic'
        label = 'í† í”½'
        df_map = df_map.copy()
        df_map['display_name'] = df_map[group_col].apply(
            lambda x: get_topic_name(content_type, category, x) if x != -1 else "Noise"
        )
    
    # âœ… 1. Noise ì œê±°
    summary = df_map[df_map['display_name'] != 'Noise'].groupby('display_name').size().reset_index(name='count')
    
    category_label = "í¥í–‰ì‘" if category == 'hit' else "ë¹„í¥í–‰ì‘"
    
    # âœ… 2. ìƒ‰ìƒ: ì—°ë…¹ìƒ‰(ë‚®ì€ ê°’) â†’ ì—°ì£¼í™©(ë†’ì€ ê°’)
    fig = px.bar(
        summary, x='display_name', y='count',
        title=f"{category_label} {content_type_label} {label}ë³„ ë¶„í¬",
        labels={'display_name': label, 'count': f'{content_type_label} ìˆ˜'},
        color='count',
        color_continuous_scale=[[0, '#c8e6c9'], [0.5, '#ffeb3b'], [1, '#ffcc80']],  # ì—°ë…¹ â†’ ì—°ë…¸ë‘ â†’ ì—°ì£¼í™©
        text='count'
    )
    
    # âœ… 3. yì¶• ì„¤ì •
    if content_type == "drama":
        yaxis_config = dict(
            title_font=dict(color='black'),
            tickfont=dict(color='black'),
            range=[0, 250],
            dtick=50
        )
    else:
        yaxis_config = dict(
            title_font=dict(color='black'),
            tickfont=dict(color='black'),
            range=[0, 1600],  # ë³€ê²½: 2000 â†’ 1600
            dtick=400
        )

    fig.update_layout(
        height=600,
        xaxis_tickangle=-45,
        plot_bgcolor='white',
        paper_bgcolor='white',
        title_font=dict(color='black', size=16),
        xaxis=dict(
            title_font=dict(color='black'),
            tickfont=dict(color='black')
        ),
        yaxis=yaxis_config
    )
    fig.update_traces(textfont=dict(color='black'), textposition='outside')
    return fig



# ========== ìƒˆë¡œìš´ í•¨ìˆ˜: ëŒ€í‘œ ì‘í’ˆ ë Œë”ë§ ==========
def render_representative_works(data, content_type, content_type_label="ë“œë¼ë§ˆ", key_prefix="drama"):
    """í† í”½/í´ëŸ¬ìŠ¤í„°ë³„ ëŒ€í‘œ ì‘í’ˆ 3ê°œ + í¬ìŠ¤í„° ì´ë¯¸ì§€ + í‚¤ì›Œë“œ íƒœê·¸"""
    
    st.markdown("### âš™ï¸ í‘œì‹œ ì„¤ì •")
    
    col1, col2 = st.columns(2)
    
    with col1:
        category = st.selectbox(
            "ë¶„ì„ ëŒ€ìƒ",
            options=['hit', 'flop'],
            format_func=lambda x: 'ğŸŸ¢ í¥í–‰ì‘ (ìƒìœ„ 20%)' if x == 'hit' else 'ğŸ”´ ë¹„í¥í–‰ì‘ (í•˜ìœ„ 20%)',
            key=f'{key_prefix}_rep_category'
        )
    
    with col2:
        view_mode = st.selectbox(
            "ë³´ê¸° ëª¨ë“œ",
            options=['topic', 'cluster'],
            format_func=lambda x: 'ğŸ¨ í† í”½ë³„' if x == 'topic' else 'ğŸ“¦ í´ëŸ¬ìŠ¤í„°ë³„',
            key=f'{key_prefix}_rep_view'
        )
    
    # ë°ì´í„° ë¡œë“œ
    df_clusters = data['hit_clusters'] if category == 'hit' else data['flop_clusters']
    df_topic_info = data['hit_topic_info'] if category == 'hit' else data['flop_topic_info']
    df_map = data['hit_map'] if category == 'hit' else data['flop_map']
    
    # ì»¬ëŸ¼ëª… í‘œì¤€í™”
    if 'í´ëŸ¬ìŠ¤í„°' in df_clusters.columns:
        cluster_col = 'í´ëŸ¬ìŠ¤í„°'
        topic_col = 'í† í”½ë²ˆí˜¸'
        keywords_col = 'í‚¤ì›Œë“œ'
    else:
        cluster_col = 'cluster'
        topic_col = 'topic_id'
        keywords_col = 'keywords'
    
    # ========== í•„í„° ë“œë¡­ë‹¤ìš´ ì¶”ê°€ (ë‹¨ì¼ ì„ íƒ) ==========
    if view_mode == 'topic':
        # í† í”½ í•„í„°
        df_topic_info_filtered = df_topic_info[df_topic_info['Topic'] != -1].copy()
        all_topics = sorted(df_topic_info_filtered['Topic'].tolist())
        
        # í† í”½ ID â†’ ì´ë¦„ ë§¤í•‘
        topic_options = {
            topic_id: get_topic_name(content_type, category, topic_id)
            for topic_id in all_topics
        }
        
        # ë‹¨ì¼ ì„ íƒ ë“œë¡­ë‹¤ìš´
        selected_topic = st.selectbox(
            "ğŸ¨ í† í”½ ì„ íƒ",
            options=['ì „ì²´'] + all_topics,
            format_func=lambda x: 'ì „ì²´ í† í”½' if x == 'ì „ì²´' else topic_options[x],
            key=f'{key_prefix}_topic_filter'
        )
        
        # ì„ íƒëœ í† í”½ë§Œ í•„í„°ë§
        if selected_topic != 'ì „ì²´':
            selected_topics = [selected_topic]
        else:
            selected_topics = all_topics
    else:
        # í´ëŸ¬ìŠ¤í„° í•„í„°
        all_clusters = sorted(df_clusters[cluster_col].unique().tolist())
        
        # í´ëŸ¬ìŠ¤í„° ID â†’ ì´ë¦„ ë§¤í•‘
        cluster_options = {
            cluster_id: get_cluster_name(content_type, category, cluster_id)
            for cluster_id in all_clusters
        }
        
        # ë‹¨ì¼ ì„ íƒ ë“œë¡­ë‹¤ìš´
        selected_cluster = st.selectbox(
            "ğŸ“¦ í´ëŸ¬ìŠ¤í„° ì„ íƒ",
            options=['ì „ì²´'] + all_clusters,
            format_func=lambda x: 'ì „ì²´ í´ëŸ¬ìŠ¤í„°' if x == 'ì „ì²´' else cluster_options[x],
            key=f'{key_prefix}_cluster_filter'
        )
        
        # ì„ íƒëœ í´ëŸ¬ìŠ¤í„°ë§Œ í•„í„°ë§
        if selected_cluster != 'ì „ì²´':
            selected_clusters = [selected_cluster]
        else:
            selected_clusters = all_clusters
    
    st.markdown("---")
    
    # ========== í¬ìŠ¤í„° ë§¤í•‘ (ìµœì í™”: í•„ìš”í•œ ê²ƒë§Œ ë¡œë“œ) ==========
    title_to_poster = {}
    
    # í•„í„°ë§ëœ í† í”½/í´ëŸ¬ìŠ¤í„°ì— í•´ë‹¹í•˜ëŠ” ì‘í’ˆë§Œ ì¶”ì¶œ
    if view_mode == 'topic':
        filtered_topic_info = df_topic_info_filtered[df_topic_info_filtered['Topic'].isin(selected_topics)]
        needed_titles = set()
        for _, row in filtered_topic_info.iterrows():
            rep_titles_raw = row.get('Representative_Docs_Titles', '')
            if isinstance(rep_titles_raw, str) and rep_titles_raw:
                needed_titles.update([t.strip() for t in rep_titles_raw.split('|')][:3])
    else:
        filtered_clusters = df_clusters[df_clusters[cluster_col].isin(selected_clusters)]
        needed_titles = set()
        for cluster_id in selected_clusters:
            cluster_topics = filtered_clusters[filtered_clusters[cluster_col] == cluster_id][topic_col].tolist()
            for topic_id in cluster_topics:
                topic_row = df_topic_info[df_topic_info['Topic'] == topic_id]
                if len(topic_row) > 0:
                    rep_titles_raw = topic_row.iloc[0].get('Representative_Docs_Titles', '')
                    if isinstance(rep_titles_raw, str) and rep_titles_raw:
                        needed_titles.update([t.strip() for t in rep_titles_raw.split('|')][:3])
    
    # ==================== render_representative_works í•¨ìˆ˜ì˜ í¬ìŠ¤í„° ë¡œë”© ë¶€ë¶„ êµì²´ ====================

    # í•„ìš”í•œ í¬ìŠ¤í„°ë§Œ ë¡œë“œ (ì„±ëŠ¥ ìµœì í™”)
    poster_loaded = False
    try:
        # ë°©ë²• 1: ë°°í¬ í™˜ê²½ ê²½ë¡œ ì‹œë„
        if content_type == "drama":
            import_path = os.path.join(BASE_DIR, "data", "embeddings", "drama_text_embedding_poster.parquet")
        else:
            import_path = os.path.join(BASE_DIR, "data", "embeddings", "movie_text_embedding_poster.parquet")

        if os.path.exists(import_path):
            df_original = pd.read_parquet(import_path, columns=["imdb_id", "title", "poster_path"])
            poster_loaded = True
        else:
            # ë°©ë²• 2: ë¡œì»¬ í™˜ê²½ ê²½ë¡œ ì‹œë„
            if content_type == "drama":
                import_path = r"C:\Users\lizzy\OneDrive\ë°”íƒ• í™”ë©´\ìµœì¢…í”Œì \ìµœì¢…ë°ì´í„°ì…‹\ìµœì¢…ë°ì´í„°ì…‹_ë“œë¼ë§ˆ\drama_text_embedding_qwen3.parquet"
            else:
                import_path = r"C:\Users\lizzy\OneDrive\ë°”íƒ• í™”ë©´\ìµœì¢…í”Œì \ìµœì¢…ë°ì´í„°ì…‹\ìµœì¢…ë°ì´í„°ì…‹_ì˜í™”\movie_text_embedding_qwen3.parquet"
            
            if os.path.exists(import_path):
                df_original = pd.read_parquet(import_path, columns=["imdb_id", "title", "poster_path"])
                poster_loaded = True

        if poster_loaded:
            # í•„ìš”í•œ ì œëª©ë§Œ ë§¤í•‘
            for title in needed_titles:
                if 'title' not in df_map.columns:
                    continue
                    
                title_row = df_map[df_map['title'] == title]
                if len(title_row) == 0:
                    continue

                imdb_id = title_row.iloc[0]["imdb_id"]
                poster_row = df_original[df_original["imdb_id"] == imdb_id]
                
                if len(poster_row) > 0 and 'poster_path' in poster_row.columns:
                    poster_path = poster_row.iloc[0]["poster_path"]
                    if pd.notna(poster_path) and poster_path:
                        title_to_poster[title] = f"https://image.tmdb.org/t/p/w300{poster_path}"
        else:
            st.info("ğŸ“Œ í¬ìŠ¤í„° ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì œëª©ë§Œ í‘œì‹œë©ë‹ˆë‹¤.")

    except Exception as e:
        st.warning(f"âš ï¸ í¬ìŠ¤í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜: {str(e)}")




    
    # ========== ì½˜í…ì¸  ë Œë”ë§ ==========
    
    if view_mode == 'topic':
        # í† í”½ë³„ í‘œì‹œ
        df_topic_info_display = df_topic_info_filtered[df_topic_info_filtered['Topic'].isin(selected_topics)]
        
        if len(df_topic_info_display) == 0:
            st.info("ğŸ“­ ì„ íƒí•œ í† í”½ì´ ì—†ìŠµë‹ˆë‹¤. ìœ„ì—ì„œ í† í”½ì„ ì„ íƒí•˜ì„¸ìš”.")
            return
        
        for idx, row in df_topic_info_display.iterrows():
            topic_id = row['Topic']
            topic_name = get_topic_name(content_type, category, topic_id)
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ (ìˆ«ì ì œê±°)
            keywords_raw = row.get('Name', '')
            keywords = []
            for kw in keywords_raw.split('_'):
                kw = kw.strip()
                # ìˆ«ìë§Œìœ¼ë¡œ ì´ë£¨ì–´ì§„ í‚¤ì›Œë“œ ì œê±°
                if kw and not kw.isdigit():
                    keywords.append(kw)
            keywords = keywords[:10]
            
            # ëŒ€í‘œ ì‘í’ˆ
            rep_titles_raw = row.get('Representative_Docs_Titles', '')
            if isinstance(rep_titles_raw, str) and rep_titles_raw:
                rep_titles = [t.strip() for t in rep_titles_raw.split('|')][:3]
            else:
                rep_titles = []
            
            # ì¹´ë“œ í—¤ë”
            st.markdown(f"""
            <div class="rep-work-card">
                <h4>ğŸ“Œ {topic_name}</h4>
                <p><strong>ì‘í’ˆ ìˆ˜:</strong> {row.get('Count', 0)}ê°œ</p>
            """, unsafe_allow_html=True)
            
            # ëŒ€í‘œ ì‘í’ˆ ì„¹ì…˜
            if rep_titles:
                st.markdown("<p><strong>ëŒ€í‘œ ì‘í’ˆ:</strong></p>", unsafe_allow_html=True)
                
                # í¬ìŠ¤í„° ì´ë¯¸ì§€ 3ê°œ (í¬ê¸° ì¦ê°€)
                cols = st.columns(len(rep_titles))
                for i, title in enumerate(rep_titles):
                    with cols[i]:
                        poster_url = title_to_poster.get(title)
                        if poster_url:
                            st.image(poster_url, width=260)  # í¬ê¸° ì¦ê°€: 220px â†’ 260px
                            st.markdown(f"<p class='movie-title' style='margin-left:0;padding-left:0;'>{title}</p>", unsafe_allow_html=True)
                        else:
                            st.markdown(f"""
                            <div style='
                                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                                width: 260px;
                                aspect-ratio: 2/3;
                                display: flex;
                                align-items: center;
                                justify-content: center;
                                color: white;
                                font-size: 12px;
                                text-align: center;
                                padding: 16px;
                                border-radius: 8px;
                                margin: 0 auto;
                            '>
                                No Poster
                            </div>
                            <p class='movie-title'>{title}</p>
                            """, unsafe_allow_html=True)
            
            # í‚¤ì›Œë“œ ì„¹ì…˜
            if keywords:
                st.markdown("<p><strong>í‚¤ì›Œë“œ:</strong></p>", unsafe_allow_html=True)
                keywords_html = " ".join([f'<span class="keyword-tag">{kw}</span>' for kw in keywords])
                st.markdown(keywords_html, unsafe_allow_html=True)
            
            st.markdown("</div>", unsafe_allow_html=True)
    
    else:
        # í´ëŸ¬ìŠ¤í„°ë³„ í‘œì‹œ
        cluster_ids_display = [c for c in sorted(df_clusters[cluster_col].unique()) if c in selected_clusters]
        
        if len(cluster_ids_display) == 0:
            st.info("ğŸ“­ ì„ íƒí•œ í´ëŸ¬ìŠ¤í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ìœ„ì—ì„œ í´ëŸ¬ìŠ¤í„°ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
            return
        
        for cluster_id in cluster_ids_display:
            cluster_name = get_cluster_name(content_type, category, cluster_id)
            
            # í•´ë‹¹ í´ëŸ¬ìŠ¤í„°ì˜ í† í”½ë“¤
            cluster_topics = df_clusters[df_clusters[cluster_col] == cluster_id][topic_col].tolist()
            
            # í‚¤ì›Œë“œ
            cluster_keywords_raw = df_clusters[df_clusters[cluster_col] == cluster_id][keywords_col].iloc[0] if keywords_col in df_clusters.columns else ''
            cluster_keywords = [kw.strip() for kw in cluster_keywords_raw.split(',') if kw.strip()][:10]
            
            # ëŒ€í‘œ ì‘í’ˆ
            rep_works = []
            for topic_id in cluster_topics:
                topic_row = df_topic_info[df_topic_info['Topic'] == topic_id]
                if len(topic_row) > 0:
                    rep_titles_raw = topic_row.iloc[0].get('Representative_Docs_Titles', '')
                    if isinstance(rep_titles_raw, str) and rep_titles_raw:
                        rep_works.extend([t.strip() for t in rep_titles_raw.split('|')])
            
            rep_works = rep_works[:3]
            
            # ì¹´ë“œ í—¤ë”
            st.markdown(f"""
            <div class="rep-work-card">
                <h4>ğŸ“¦ {cluster_name}</h4>
                <p><strong>í¬í•¨ í† í”½:</strong> {', '.join([str(t) for t in cluster_topics])}</p>
            """, unsafe_allow_html=True)
            
            # ëŒ€í‘œ ì‘í’ˆ ì„¹ì…˜
            if rep_works:
                st.markdown("<p><strong>ëŒ€í‘œ ì‘í’ˆ:</strong></p>", unsafe_allow_html=True)
                
                # í¬ìŠ¤í„° ì´ë¯¸ì§€ (í¬ê¸° ì¦ê°€)
                cols = st.columns(len(rep_works))
                for i, title in enumerate(rep_works):
                    with cols[i]:
                        poster_url = title_to_poster.get(title)
                        if poster_url:
                            st.image(poster_url, width=260)  # í¬ê¸° ì¦ê°€: 220px â†’ 260px
                            st.markdown(f"<p class='movie-title' style='margin-left:0;padding-left:0;'>{title}</p>", unsafe_allow_html=True)
                        else:
                            st.markdown(f"""
                            <div style='
                                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                                width: 260px;
                                aspect-ratio: 2/3;
                                display: flex;
                                align-items: center;
                                justify-content: center;
                                color: white;
                                font-size: 12px;
                                text-align: center;
                                padding: 16px;
                                border-radius: 8px;
                                margin: 0 auto;
                            '>
                                No Poster
                            </div>
                            <p class='movie-title'>{title}</p>
                            """, unsafe_allow_html=True)
            
            # í‚¤ì›Œë“œ ì„¹ì…˜
            if cluster_keywords:
                st.markdown("<p><strong>í‚¤ì›Œë“œ:</strong></p>", unsafe_allow_html=True)
                keywords_html = " ".join([f'<span class="keyword-tag">{kw}</span>' for kw in cluster_keywords])
                st.markdown(keywords_html, unsafe_allow_html=True)
            
            st.markdown("</div>", unsafe_allow_html=True)


def render_bertopic_section(data, content_type, content_type_label="ë“œë¼ë§ˆ", key_prefix="drama"):
    """BERTopic ë¶„ì„ ì„¹ì…˜ ë Œë”ë§ - í† í”½ ìƒì„¸ ì •ë³´ ì œê±°"""
    
    st.markdown("### âš™ï¸ ì‹œê°í™” ì„¤ì •")
    
    col1, col2 = st.columns(2)
    
    with col1:
        category = st.selectbox(
            "ë¶„ì„ ëŒ€ìƒ",
            options=['hit', 'flop'],
            format_func=lambda x: 'ğŸŸ¢ í¥í–‰ì‘ (ìƒìœ„ 20%)' if x == 'hit' else 'ğŸ”´ ë¹„í¥í–‰ì‘ (í•˜ìœ„ 20%)',
            key=f'{key_prefix}_category'
        )
    
    with col2:
        view_mode = st.selectbox(
            "ë³´ê¸° ëª¨ë“œ",
            options=['cluster', 'topic'],
            format_func=lambda x: 'ğŸ“¦ í´ëŸ¬ìŠ¤í„°' if x == 'cluster' else 'ğŸ¨ í† í”½',
            key=f'{key_prefix}_view_mode'
        )
    
    df_map = data['hit_map'] if category == 'hit' else data['flop_map']
    df_clusters = data['hit_clusters'] if category == 'hit' else data['flop_clusters']
    df_topic_info = data['hit_topic_info'] if category == 'hit' else data['flop_topic_info']
    
    if 'í´ëŸ¬ìŠ¤í„°' in df_clusters.columns:
        cluster_col = 'í´ëŸ¬ìŠ¤í„°'
        topic_col = 'í† í”½ë²ˆí˜¸'
    else:
        cluster_col = 'cluster'
        topic_col = 'topic_id'
    
    if view_mode == 'cluster':
        if 'cluster' not in df_map.columns:
            topic_to_cluster = dict(zip(
                df_clusters[topic_col], 
                df_clusters[cluster_col]
            ))
            df_map = df_map.copy()
            df_map['cluster'] = df_map['topic'].map(topic_to_cluster).fillna(-1).astype(int)
        
        all_items = sorted([c for c in df_map['cluster'].unique().tolist() if c != -1])
        format_func = lambda x: get_cluster_name(content_type, category, x)
        filter_label = "í´ëŸ¬ìŠ¤í„° í•„í„° (ì „ì²´ ë³´ë ¤ë©´ ë¹„ì›Œë‘ì„¸ìš”)"
    else:
        all_items = sorted([t for t in df_map['topic'].unique().tolist() if t != -1])
        format_func = lambda x: get_topic_name(content_type, category, x)
        filter_label = "í† í”½ í•„í„° (ì „ì²´ ë³´ë ¤ë©´ ë¹„ì›Œë‘ì„¸ìš”)"
    
    selected_items = st.multiselect(
        filter_label,
        options=all_items,
        default=all_items,
        format_func=format_func,
        key=f'{key_prefix}_items'
    )
    
    st.markdown("---")
    
    # ë©”íŠ¸ë¦­
    col_m1, col_m2 = st.columns(2)
    
    total_items = len(df_map)
    total_groups = len(all_items)
    group_label = "í´ëŸ¬ìŠ¤í„°" if view_mode == 'cluster' else "í† í”½"
    category_emoji = "ğŸŸ¢" if category == "hit" else "ğŸ”´"
    category_text = "í¥í–‰ì‘" if category == "hit" else "ë¹„í¥í–‰ì‘"
    
    with col_m1:
        st.metric(f"{category_emoji} {category_text} {content_type_label}", total_items)
    with col_m2:
        st.metric(f"{category_emoji} {category_text} {group_label}", total_groups)
    
    st.markdown("---")
    
    # Topic Map
    st.markdown(f"#### ğŸ“Š {group_label} Map")
    fig_map = create_topic_map(
        df_map, df_clusters, category, selected_items,
        view_mode, content_type, content_type_label
    )
    st.plotly_chart(fig_map, use_container_width=True)
    
    st.markdown("---")

    # âœ… 3. í‚¤ì›Œë“œ ë¹„êµ (ìˆœì„œ ë³€ê²½: ë¶„í¬ ë‹¤ìŒìœ¼ë¡œ)
    if 'keyword_comparison' in data and data['keyword_comparison'] is not None:
        st.markdown("#### ğŸ” í¥í–‰ì‘ vs ë¹„í¥í–‰ì‘ í‚¤ì›Œë“œ ë¹„êµ")
        st.markdown('''
        **í•´ì„ ê°€ì´ë“œ:**
        - **í¥í–‰ì‘ ê³ ìœ  í‚¤ì›Œë“œ**: í¥í–‰ì‘ì—ì„œë§Œ ìì£¼ ë“±ì¥í•˜ëŠ” í‚¤ì›Œë“œ
        - **ë¹„í¥í–‰ì‘ ê³ ìœ  í‚¤ì›Œë“œ**: ë¹„í¥í–‰ì‘ì—ì„œë§Œ ìì£¼ ë“±ì¥í•˜ëŠ” í‚¤ì›Œë“œ
        ''')
        top_n = st.slider("í‘œì‹œí•  í‚¤ì›Œë“œ ìˆ˜", 10, 50, 20, 5, key=f'{key_prefix}_topn')
        fig_kw = create_keyword_comparison_chart(data['keyword_comparison'], top_n)
        st.plotly_chart(fig_kw, use_container_width=True)
    
    # âœ… 2. ë¶„í¬ (ìˆœì„œ ë³€ê²½: í‚¤ì›Œë“œ ë¹„êµë³´ë‹¤ ë¨¼ì €)
    st.markdown(f"#### ğŸ“ˆ {group_label}ë³„ ë¶„í¬")
    fig_dist = create_distribution_chart(df_map, view_mode, category, content_type, content_type_label)
    st.plotly_chart(fig_dist, use_container_width=True)
    
    st.markdown("---")
    
    
    


# =============================================================================
# ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
# =============================================================================

@st.cache_data
def load_drama_bertopic_data():
    """ë“œë¼ë§ˆ BERTopic ë°ì´í„° ë¡œë“œ"""
    try:
        base_path = "data/02_synopsis/drama"
        
        data = {
            'hit_map': pd.read_csv(f"{base_path}/hit_umap_map.csv"),
            'flop_map': pd.read_csv(f"{base_path}/flop_umap_map.csv"),
            'hit_clusters': pd.read_csv(f"{base_path}/hit_clusters.csv"),
            'flop_clusters': pd.read_csv(f"{base_path}/flop_clusters.csv"),
            'hit_topic_info': pd.read_csv(f"{base_path}/hit_topic_info.csv"),
            'flop_topic_info': pd.read_csv(f"{base_path}/flop_topic_info.csv"),
        }
        
        try:
            data['keyword_comparison'] = pd.read_csv(f"{base_path}/keyword_comparison.csv")
        except FileNotFoundError:
            data['keyword_comparison'] = None
        
        return data
    except FileNotFoundError:
        return None


@st.cache_data
def load_movie_bertopic_data():
    """ì˜í™” BERTopic ë°ì´í„° ë¡œë“œ"""
    base_path = "data/02_synopsis/movie"

    try:
        if os.path.exists(f"{base_path}/hit_umap_map.csv"):
            hit_map = pd.read_csv(f"{base_path}/hit_umap_map.csv")
        else:
            hit_map = pd.read_csv(f"{base_path}/hit_topic_info.csv")
            hit_map = hit_map.rename(columns={"Topic": "topic"})
            hit_map["title"] = ""

        if os.path.exists(f"{base_path}/flop_umap_map.csv"):
            flop_map = pd.read_csv(f"{base_path}/flop_umap_map.csv")
        else:
            flop_map = pd.read_csv(f"{base_path}/flop_topic_info.csv")
            flop_map = flop_map.rename(columns={"Topic": "topic"})
            flop_map["title"] = ""

        data = {
            "hit_map": hit_map,
            "flop_map": flop_map,
            "hit_clusters": pd.read_csv(f"{base_path}/hit_clusters.csv"),
            "flop_clusters": pd.read_csv(f"{base_path}/flop_clusters.csv"),
            "hit_topic_info": pd.read_csv(f"{base_path}/hit_topic_info.csv"),
            "flop_topic_info": pd.read_csv(f"{base_path}/flop_topic_info.csv"),
        }

        try:
            data["keyword_comparison"] = pd.read_csv(f"{base_path}/keyword_comparison.csv")
        except FileNotFoundError:
            data["keyword_comparison"] = None

        return data

    except FileNotFoundError:
        return None


# =============================================================================
# ë©”ì¸ ì½˜í…ì¸ 
# =============================================================================

main_tab1, main_tab2 = st.tabs(["ğŸ¬ ì˜í™”", "ğŸ“º ë“œë¼ë§ˆ"])

# ì˜í™” íƒ­
with main_tab1:
    st.header("ğŸ¬ ì˜í™” ì¤„ê±°ë¦¬ ë¶„ì„")
    
    movie_tab1, movie_tab2, movie_tab3 = st.tabs(["ğŸ“Š TF-IDF ë¶„ì„", "ğŸ¯ BERTopic í´ëŸ¬ìŠ¤í„°", "ğŸ¬ ëŒ€í‘œ ì‘í’ˆ"])
    
    with movie_tab1:
        st.subheader("ğŸ¬ ì˜í™” TF-IDF í‚¤ì›Œë“œ")
        st.markdown("â€» ë‹¨ì–´ ë¹ˆë„ê°€ ë†’ì„ìˆ˜ë¡ í¬ê²Œ í‘œí˜„ë©ë‹ˆë‹¤. ìƒìœ„ 30ê°œ í‚¤ì›Œë“œë§Œ í‘œì‹œë©ë‹ˆë‹¤.")
        st.markdown("---")

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("### ğŸŸ¢ í¥í–‰ì‘ í‚¤ì›Œë“œ")
            df_hit = load_tfidf_keywords("movie", "hit")
            img = generate_wordcloud_image(df_hit, color_palette=["#fc8d59", "#f781bf", "#ff4c42"], font_path=FONT_PATH)
            st.image(img)
        with col2:
            st.markdown("### ğŸ”´ ë¹„í¥í–‰ì‘ í‚¤ì›Œë“œ")
            df_flop = load_tfidf_keywords("movie", "flop")
            img = generate_wordcloud_image(df_flop, color_palette=["#4d4d4d", "#91bfdb", "#c2a5cf"], font_path=FONT_PATH)
            st.image(img)

    with movie_tab2:
        st.markdown("***í¥í–‰ì‘: hit_score ìƒìœ„ 20% / ë¹„í¥í–‰ì‘: hit_score í•˜ìœ„ 20%***")
        st.markdown("---")
        
        movie_data = load_movie_bertopic_data()
        if movie_data is None:
            st.error("âš ï¸ ì˜í™” BERTopic ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            render_bertopic_section(movie_data, content_type="movie", content_type_label="ì˜í™”", key_prefix="movie")
    
    with movie_tab3:
        st.markdown("***í¥í–‰ì‘: hit_score ìƒìœ„ 20% / ë¹„í¥í–‰ì‘: hit_score í•˜ìœ„ 20%***")
        st.markdown("---")
        
        movie_data = load_movie_bertopic_data()
        if movie_data is None:
            st.error("âš ï¸ ì˜í™” BERTopic ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            render_representative_works(movie_data, content_type="movie", content_type_label="ì˜í™”", key_prefix="movie")

# ë“œë¼ë§ˆ íƒ­
with main_tab2:
    st.header("ğŸ“º ë“œë¼ë§ˆ ì¤„ê±°ë¦¬ ë¶„ì„")
    
    drama_tab1, drama_tab2, drama_tab3 = st.tabs(["ğŸ“Š TF-IDF ë¶„ì„", "ğŸ¯ BERTopic í´ëŸ¬ìŠ¤í„°", "ğŸ¬ ëŒ€í‘œ ì‘í’ˆ"])
    
    with drama_tab1:
        st.subheader("ğŸ“º ë“œë¼ë§ˆ TF-IDF í‚¤ì›Œë“œ")
        st.markdown("â€» ë‹¨ì–´ ë¹ˆë„ê°€ ë†’ì„ìˆ˜ë¡ í¬ê²Œ í‘œí˜„ë©ë‹ˆë‹¤. ìƒìœ„ 30ê°œ í‚¤ì›Œë“œë§Œ í‘œì‹œë©ë‹ˆë‹¤.")
        st.markdown("---")

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("### ğŸŸ¢ í¥í–‰ì‘ í‚¤ì›Œë“œ")
            df_hit = load_tfidf_keywords("drama", "hit")
            img = generate_wordcloud_image(df_hit, color_palette=["#d73027", "#fc8d59", "#f781bf"], font_path=FONT_PATH)
            st.image(img)
        with col2:
            st.markdown("### ğŸ”´ ë¹„í¥í–‰ì‘ í‚¤ì›Œë“œ")
            df_flop = load_tfidf_keywords("drama", "flop")
            img = generate_wordcloud_image(df_flop, color_palette=["#4d4d4d", "#91bfdb", "#c2a5cf"], font_path=FONT_PATH)
            st.image(img)
        
    with drama_tab2:
        st.markdown("***í¥í–‰ì‘: hit_score ìƒìœ„ 20% / ë¹„í¥í–‰ì‘: hit_score í•˜ìœ„ 20%***")
        st.markdown("---")
        
        drama_data = load_drama_bertopic_data()
        if drama_data is None:
            st.error("âš ï¸ ë“œë¼ë§ˆ BERTopic ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            render_bertopic_section(drama_data, content_type="drama", content_type_label="ë“œë¼ë§ˆ", key_prefix="drama")
    
    with drama_tab3:
        st.markdown("***í¥í–‰ì‘: hit_score ìƒìœ„ 20% / ë¹„í¥í–‰ì‘: hit_score í•˜ìœ„ 20%***")
        st.markdown("---")
        
        drama_data = load_drama_bertopic_data()
        if drama_data is None:
            st.error("âš ï¸ ë“œë¼ë§ˆ BERTopic ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            render_representative_works(drama_data, content_type="drama", content_type_label="ë“œë¼ë§ˆ", key_prefix="drama")